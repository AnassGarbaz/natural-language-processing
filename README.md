# natural-language-processing

## Preprocessing folder 

Contain 3 files :

tp1 is for :

 * TF and TFIDF 
 * TERM DOCUMENT MATRIX
 * Application for shakespeare_corpus.

tp2 is for :

 * Word_Embedding,  Analogies, Visualization
 * word2vec
 * fasttext
 * glove_google_news_300.ipynb

TP2_nlp is for :

 * Loading webtext corpus
 * Handle stop words, punctuations and emojis
 * most common words
 
 ## Topic detection folder 

  Topic detection in the brown corpus

 ## imbalaced datasets and data augmentation folder
 
  in This folder i handled imbalaced datasets using :  
  
   * Random over-sampling
   * SMOTE (Synthetic Minority Over-Sampling Technique) 
   * Downsampling :
     - RandomUnderSampler.
     - NearMiss-1.
     
  I made also data augmentation using 2 libraries, nlpaug and textaugment. I used also multiple techniques as :
  
  for word augmentation :
  
   * Thesausus
   * Word embedings augmenter
   * Back Translation
   * Contextual Word Embeddings Augmenter
   
  For sentence Augmentation :
  
   * Text generation
   * Contextual Word Embeddings for Sentence Augmenter
   * Abstractive Summarization Augmenter
   
  For Character Augmentation :
  
   * OCR Augmenter
   * Random Augmenter
 
  
  
   
